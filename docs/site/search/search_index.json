{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"contributing/","title":"\ud83c\udf31 Developing guide","text":""},{"location":"contributing/#branching","title":"\ud80c\uddb1 Branching","text":"<p>See here the approach to creating branches that is used in the repository.</p>"},{"location":"contributing/#naming-commits","title":"\ud83d\udc8e Naming commits","text":"<ul> <li><code>add</code> means adding functionality</li> <li><code>remove</code> means removing functionality</li> <li><code>change</code> means normal changing</li> <li><code>bug</code> means fixing bug</li> <li><code>arch</code> means changing architecture (usually to be compatible with langchain or other open-source projects)</li> </ul>"},{"location":"contributing/#style-hints","title":"Style hints","text":"<ul> <li>Try to use naming semantic only once, change the following code:</li> </ul> Deprecated Recommended <code>node_amendment</code> <code>node</code> <code>children_amendment</code> <code>children</code> <pre><code>class NodeAmendmentPropagation(BaseModel):\n    \"\"\"Propagation of amendment among children\"\"\"\n\n    node_amendment: DataType\n    \"\"\"Node amendment\"\"\"\n\n    children_amendment: Dict[EdgeType, DataType]\n    \"\"\"Children amendment mapping\"\"\"\n</code></pre> <p>This also applies to file names to some extent</p> <ul> <li> <p>It will be good if the hyperlinks move to single puku-core page. If so, try to mirror puku -&gt; puku-core according to this principle, minimizing the number of files globally.</p> </li> <li> <p>Try to group the code in puku files with the same semantics, which is not present in puku-core.</p> </li> </ul>"},{"location":"concepts/memory/","title":"Memory","text":"<p>It is a good idea to use writing nightly with full-tree search, it could be expensive.</p>"},{"location":"core/api/","title":"API Reference","text":"<p>Similar name as for true species</p>"},{"location":"core/api/#puku_core.documents.transformers.BaseBlobTransformer","title":"<code>BaseBlobTransformer</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for blob transformation.</p> <p>A blob transformation takes a sequence of blobs and returns a sequence of transformed blobs.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>class BaseBlobTransformer(ABC):\n    \"\"\"Abstract base class for blob transformation.\n\n    A blob transformation takes a sequence of blobs and returns a\n    sequence of transformed blobs.\n    \"\"\"\n\n    @abstractmethod\n    def transform_blobs(self, blobs: Sequence[Blob], **kwargs: Any) -&gt; Sequence[Blob]:\n        \"\"\"Transform a list of blobs.\n\n        Args:\n            blobs: A sequence of blobs to be transformed.\n\n        Returns:\n            A sequence of transformed blobs.\n        \"\"\"\n\n    async def atransform_blobs(\n        self, blobs: Sequence[Blob], **kwargs: Any\n    ) -&gt; Sequence[Blob]:\n        \"\"\"Asynchronously transform a list of blobs.\n\n        Args:\n            blobs: A sequence of blobs to be transformed.\n\n        Returns:\n            A sequence of transformed blobs.\n        \"\"\"\n        return await run_in_executor(None, self.transform_blobs, blobs, **kwargs)\n</code></pre>"},{"location":"core/api/#puku_core.documents.transformers.BaseBlobTransformer.atransform_blobs","title":"<code>atransform_blobs(blobs, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously transform a list of blobs.</p> <p>Parameters:</p> Name Type Description Default <code>blobs</code> <code>Sequence[Blob]</code> <p>A sequence of blobs to be transformed.</p> required <p>Returns:</p> Type Description <code>Sequence[Blob]</code> <p>A sequence of transformed blobs.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>async def atransform_blobs(\n    self, blobs: Sequence[Blob], **kwargs: Any\n) -&gt; Sequence[Blob]:\n    \"\"\"Asynchronously transform a list of blobs.\n\n    Args:\n        blobs: A sequence of blobs to be transformed.\n\n    Returns:\n        A sequence of transformed blobs.\n    \"\"\"\n    return await run_in_executor(None, self.transform_blobs, blobs, **kwargs)\n</code></pre>"},{"location":"core/api/#puku_core.documents.transformers.BaseBlobTransformer.transform_blobs","title":"<code>transform_blobs(blobs, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Transform a list of blobs.</p> <p>Parameters:</p> Name Type Description Default <code>blobs</code> <code>Sequence[Blob]</code> <p>A sequence of blobs to be transformed.</p> required <p>Returns:</p> Type Description <code>Sequence[Blob]</code> <p>A sequence of transformed blobs.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>@abstractmethod\ndef transform_blobs(self, blobs: Sequence[Blob], **kwargs: Any) -&gt; Sequence[Blob]:\n    \"\"\"Transform a list of blobs.\n\n    Args:\n        blobs: A sequence of blobs to be transformed.\n\n    Returns:\n        A sequence of transformed blobs.\n    \"\"\"\n</code></pre>"},{"location":"core/api/#puku_core.documents.transformers.SubprocessBlobTransformer","title":"<code>SubprocessBlobTransformer</code>","text":"<p>               Bases: <code>BaseBlobTransformer</code>, <code>BaseModel</code></p> <p>Transform each blob in the subprocess by calling the command.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>class SubprocessBlobTransformer(BaseBlobTransformer, BaseModel):\n    \"\"\"Transform each blob in the subprocess by calling the command.\"\"\"\n\n    timeout: int = 1\n\n    def run_commands(\n        self, commands: Iterable[list[str]], blobs: Iterable[Blob]\n    ) -&gt; Sequence[Blob]:\n        \"\"\"Run commands and return successfuly transformed blobs.\n\n        Args:\n            commands (Sequence[list[str]]): Pandoc commands.\n            blobs (Sequence[Blob]): Output blobs to be returned.\n\n        Returns:\n            Sequence[Blob]: Output blobs that transformed successfully.\n        \"\"\"\n\n        successfuly_transformed_blobs: list[Blob] = []\n\n        for command, blob in zip(commands, blobs):\n            try:\n                run(command, timeout=self.timeout)\n                successfuly_transformed_blobs.append(blob)\n            except Exception:\n                continue\n\n        return successfuly_transformed_blobs\n\n    @abstractmethod\n    def get_output_blob(self, blob: Blob, **kwargs) -&gt; Blob:\n        \"\"\"Generate output blob.\n\n        Args:\n            blob (Blob): Input blob.\n\n        Returns:\n            Blob: Output blob to be returned in `transform_blobs`.\n        \"\"\"\n\n    @abstractmethod\n    def get_command(self, blob: Blob, **kwargs) -&gt; list[str]:\n        \"\"\"Generate a command that will be executed in the subprocess.\n\n        Args:\n            blob (Blob): Input blob.\n\n        Returns:\n            list[str]: Returned command.\n        \"\"\"\n\n    def transform_blobs(self, blobs: Sequence[Blob], **kwargs: Any) -&gt; Sequence[Blob]:\n        \"\"\"Transform blobs. For now, just run the commands in subprocess and return the created blobs.\n\n        Args:\n            blobs (Sequence[Blob]): Blobs to be transformed\n\n        Returns:\n            Sequence[Blob]: Output blobs that transformed successfully.\n        \"\"\"\n\n        if \"blob\" in kwargs:\n            raise ValueError(\"`blob` argument can't be in kwargs\")\n\n        output_blobs = map(partial(self.get_output_blob, **kwargs), blobs)\n        commands = map(partial(self.get_command, **kwargs), blobs)\n\n        return self.run_commands(commands=commands, blobs=output_blobs)\n</code></pre>"},{"location":"core/api/#puku_core.documents.transformers.SubprocessBlobTransformer.get_command","title":"<code>get_command(blob, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Generate a command that will be executed in the subprocess.</p> <p>Parameters:</p> Name Type Description Default <code>blob</code> <code>Blob</code> <p>Input blob.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: Returned command.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>@abstractmethod\ndef get_command(self, blob: Blob, **kwargs) -&gt; list[str]:\n    \"\"\"Generate a command that will be executed in the subprocess.\n\n    Args:\n        blob (Blob): Input blob.\n\n    Returns:\n        list[str]: Returned command.\n    \"\"\"\n</code></pre>"},{"location":"core/api/#puku_core.documents.transformers.SubprocessBlobTransformer.get_output_blob","title":"<code>get_output_blob(blob, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Generate output blob.</p> <p>Parameters:</p> Name Type Description Default <code>blob</code> <code>Blob</code> <p>Input blob.</p> required <p>Returns:</p> Name Type Description <code>Blob</code> <code>Blob</code> <p>Output blob to be returned in <code>transform_blobs</code>.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>@abstractmethod\ndef get_output_blob(self, blob: Blob, **kwargs) -&gt; Blob:\n    \"\"\"Generate output blob.\n\n    Args:\n        blob (Blob): Input blob.\n\n    Returns:\n        Blob: Output blob to be returned in `transform_blobs`.\n    \"\"\"\n</code></pre>"},{"location":"core/api/#puku_core.documents.transformers.SubprocessBlobTransformer.run_commands","title":"<code>run_commands(commands, blobs)</code>","text":"<p>Run commands and return successfuly transformed blobs.</p> <p>Parameters:</p> Name Type Description Default <code>commands</code> <code>Sequence[list[str]]</code> <p>Pandoc commands.</p> required <code>blobs</code> <code>Sequence[Blob]</code> <p>Output blobs to be returned.</p> required <p>Returns:</p> Type Description <code>Sequence[Blob]</code> <p>Sequence[Blob]: Output blobs that transformed successfully.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>def run_commands(\n    self, commands: Iterable[list[str]], blobs: Iterable[Blob]\n) -&gt; Sequence[Blob]:\n    \"\"\"Run commands and return successfuly transformed blobs.\n\n    Args:\n        commands (Sequence[list[str]]): Pandoc commands.\n        blobs (Sequence[Blob]): Output blobs to be returned.\n\n    Returns:\n        Sequence[Blob]: Output blobs that transformed successfully.\n    \"\"\"\n\n    successfuly_transformed_blobs: list[Blob] = []\n\n    for command, blob in zip(commands, blobs):\n        try:\n            run(command, timeout=self.timeout)\n            successfuly_transformed_blobs.append(blob)\n        except Exception:\n            continue\n\n    return successfuly_transformed_blobs\n</code></pre>"},{"location":"core/api/#puku_core.documents.transformers.SubprocessBlobTransformer.transform_blobs","title":"<code>transform_blobs(blobs, **kwargs)</code>","text":"<p>Transform blobs. For now, just run the commands in subprocess and return the created blobs.</p> <p>Parameters:</p> Name Type Description Default <code>blobs</code> <code>Sequence[Blob]</code> <p>Blobs to be transformed</p> required <p>Returns:</p> Type Description <code>Sequence[Blob]</code> <p>Sequence[Blob]: Output blobs that transformed successfully.</p> Source code in <code>puku_core/documents/transformers.py</code> <pre><code>def transform_blobs(self, blobs: Sequence[Blob], **kwargs: Any) -&gt; Sequence[Blob]:\n    \"\"\"Transform blobs. For now, just run the commands in subprocess and return the created blobs.\n\n    Args:\n        blobs (Sequence[Blob]): Blobs to be transformed\n\n    Returns:\n        Sequence[Blob]: Output blobs that transformed successfully.\n    \"\"\"\n\n    if \"blob\" in kwargs:\n        raise ValueError(\"`blob` argument can't be in kwargs\")\n\n    output_blobs = map(partial(self.get_output_blob, **kwargs), blobs)\n    commands = map(partial(self.get_command, **kwargs), blobs)\n\n    return self.run_commands(commands=commands, blobs=output_blobs)\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.types.NodeAmendmentPropagation","title":"<code>NodeAmendmentPropagation</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[EdgeType, DataType]</code></p> <p>Propagation of amendment among children</p> Source code in <code>puku_core/graphs/knowledge_trees/types.py</code> <pre><code>class NodeAmendmentPropagation(BaseModel, Generic[EdgeType, DataType]):\n    \"\"\"Propagation of amendment among children\"\"\"\n\n    node: DataType\n    \"\"\"Node amendment\"\"\"\n\n    children: Dict[EdgeType, DataType]\n    \"\"\"Children amendment mapping\"\"\"\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.types.NodeAmendmentPropagation.children","title":"<code>children</code>  <code>instance-attribute</code>","text":"<p>Children amendment mapping</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.types.NodeAmendmentPropagation.node","title":"<code>node</code>  <code>instance-attribute</code>","text":"<p>Node amendment</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.types.UpdateRequest","title":"<code>UpdateRequest</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[NodeType, DataType]</code></p> <p>Knowledge tree node update request.</p> Source code in <code>puku_core/graphs/knowledge_trees/types.py</code> <pre><code>class UpdateRequest(BaseModel, Generic[NodeType, DataType]):\n    \"\"\"Knowledge tree node update request.\"\"\"\n\n    node: NodeType\n    \"\"\"Root node in the knowledge tree\"\"\"\n\n    amendment: DataType\n    \"\"\"Information to be stored\"\"\"\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.types.UpdateRequest.amendment","title":"<code>amendment</code>  <code>instance-attribute</code>","text":"<p>Information to be stored</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.types.UpdateRequest.node","title":"<code>node</code>  <code>instance-attribute</code>","text":"<p>Root node in the knowledge tree</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.writers.base.BaseAmendmentSplitter","title":"<code>BaseAmendmentSplitter</code>","text":"<p>               Bases: <code>RunnableSerializable</code></p> <p>A component for splitting node amendment</p> Source code in <code>puku_core/graphs/knowledge_trees/writers/base.py</code> <pre><code>class BaseAmendmentSplitter(RunnableSerializable):\n    \"\"\"A component for splitting node amendment\"\"\"\n\n    def invoke(\n        self,\n        input: UpdateRequest,\n        config: RunnableConfig | None = None,\n        **kwargs,\n    ) -&gt; NodeAmendmentPropagation:\n        \"\"\"Split node amendment so that you can write it to the children later\n\n        Args:\n            input (UpdateRequest): Amendment to be splitted\n        \"\"\"\n\n        raise NotImplementedError\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.writers.base.BaseAmendmentSplitter.invoke","title":"<code>invoke(input, config=None, **kwargs)</code>","text":"<p>Split node amendment so that you can write it to the children later</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>UpdateRequest</code> <p>Amendment to be splitted</p> required Source code in <code>puku_core/graphs/knowledge_trees/writers/base.py</code> <pre><code>def invoke(\n    self,\n    input: UpdateRequest,\n    config: RunnableConfig | None = None,\n    **kwargs,\n) -&gt; NodeAmendmentPropagation:\n    \"\"\"Split node amendment so that you can write it to the children later\n\n    Args:\n        input (UpdateRequest): Amendment to be splitted\n    \"\"\"\n\n    raise NotImplementedError\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.writers.base.BaseKnowledgeWriter","title":"<code>BaseKnowledgeWriter</code>","text":"<p>               Bases: <code>RunnableSerializable</code></p> <p>A component for memorizing knowledge in a knowledge tree</p> Source code in <code>puku_core/graphs/knowledge_trees/writers/base.py</code> <pre><code>class BaseKnowledgeWriter(RunnableSerializable):\n    \"\"\"A component for memorizing knowledge in a knowledge tree\"\"\"\n\n    def invoke(\n        self, input: UpdateRequest, config: RunnableConfig | None = None, **kwargs\n    ) -&gt; Any:\n        \"\"\"Memorize knowledge in a knowledge tree\n\n        Args:\n            input (Any): Node update request\n\n        \"\"\"\n\n        raise NotImplementedError\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.writers.base.BaseKnowledgeWriter.invoke","title":"<code>invoke(input, config=None, **kwargs)</code>","text":"<p>Memorize knowledge in a knowledge tree</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>Node update request</p> required Source code in <code>puku_core/graphs/knowledge_trees/writers/base.py</code> <pre><code>def invoke(\n    self, input: UpdateRequest, config: RunnableConfig | None = None, **kwargs\n) -&gt; Any:\n    \"\"\"Memorize knowledge in a knowledge tree\n\n    Args:\n        input (Any): Node update request\n\n    \"\"\"\n\n    raise NotImplementedError\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.edges.base.BaseEdge","title":"<code>BaseEdge</code>","text":"<p>               Bases: <code>UUIDHashable</code>, <code>Serializable</code>, <code>Generic[NodeType]</code></p> <p>Base edge generic for storing edge-based structural information about the tree.</p> <p>It is not yet clear what structural information may be needed in the edges.             But it is clear that it will redefine the BaseNode with strict TypeEdge typing (without generic)</p> Source code in <code>puku_core/graphs/knowledge_trees/edges/base.py</code> <pre><code>class BaseEdge(UUIDHashable, Serializable, Generic[NodeType]):\n    \"\"\"Base edge generic for storing edge-based structural information about the tree.\n\n        It is not yet clear what structural information may be needed in the edges. \\\n            But it is clear that it will redefine the BaseNode with strict TypeEdge typing (without generic)\n    \"\"\"\n\n    child: NodeType\n\n    @classmethod\n    def is_lc_serializable(cls) -&gt; bool:\n        return True\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.edges.metadata.EdgeWithMetadata","title":"<code>EdgeWithMetadata</code>","text":"<p>               Bases: <code>Serializable</code>, <code>Generic[NodeType, EdgeMetadataType]</code></p> <p>Wrapper class combining edge and metadata</p> Source code in <code>puku_core/graphs/knowledge_trees/edges/metadata.py</code> <pre><code>class EdgeWithMetadata(Serializable, Generic[NodeType, EdgeMetadataType]):\n    \"\"\"Wrapper class combining edge and metadata\"\"\"\n\n    edge: BaseEdge[NodeType]\n    metadata: EdgeMetadataType\n\n    def __hash__(self) -&gt; int:\n        return hash(self.edge)\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.true.TrueTreeNode","title":"<code>TrueTreeNode</code>","text":"<p>               Bases: <code>BaseNode</code>, <code>Generic[EdgeMetadataType]</code></p> Source code in <code>puku_core/graphs/knowledge_trees/nodes/true.py</code> <pre><code>class TrueTreeNode(BaseNode, Generic[EdgeMetadataType]):\n    children: List[EdgeWithMetadata[Self, EdgeMetadataType]] = Field(\n        default_factory=list\n    )\n\n    def descendants(self) -&gt; List[TraversalNode[Self, EdgeMetadataType]]:\n        \"\"\"Return descendants in breadth-first search (BFS) traversal order.\"\"\"\n        traversal: List[TraversalNode] = [TraversalNode(node=self)]\n        queue: List[Self] = [self]\n\n        while queue:\n            current_node = queue.pop(0)\n            for edge_with_metadata in current_node.children:\n                traversal.append(\n                    TraversalNode(\n                        node=edge_with_metadata.edge.child,\n                        parent=current_node,\n                        edge=edge_with_metadata,\n                    )\n                )\n                queue.append(edge_with_metadata.edge.child)\n\n        return traversal\n\n    def __hash__(self) -&gt; int:\n        return super().__hash__()\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.true.TrueTreeNode.descendants","title":"<code>descendants()</code>","text":"<p>Return descendants in breadth-first search (BFS) traversal order.</p> Source code in <code>puku_core/graphs/knowledge_trees/nodes/true.py</code> <pre><code>def descendants(self) -&gt; List[TraversalNode[Self, EdgeMetadataType]]:\n    \"\"\"Return descendants in breadth-first search (BFS) traversal order.\"\"\"\n    traversal: List[TraversalNode] = [TraversalNode(node=self)]\n    queue: List[Self] = [self]\n\n    while queue:\n        current_node = queue.pop(0)\n        for edge_with_metadata in current_node.children:\n            traversal.append(\n                TraversalNode(\n                    node=edge_with_metadata.edge.child,\n                    parent=current_node,\n                    edge=edge_with_metadata,\n                )\n            )\n            queue.append(edge_with_metadata.edge.child)\n\n    return traversal\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.traversal.TraversalNode","title":"<code>TraversalNode</code>","text":"<p>               Bases: <code>Serializable</code>, <code>Generic[NodeType, EdgeMetadataType]</code></p> <p>A Node with metadata returned during various traversals of the tree</p> Source code in <code>puku_core/graphs/knowledge_trees/nodes/traversal.py</code> <pre><code>class TraversalNode(Serializable, Generic[NodeType, EdgeMetadataType]):\n    \"\"\"A Node with metadata returned during various traversals of the tree\"\"\"\n\n    node: NodeType\n    \"\"\"Node itself\"\"\"\n    parent: Optional[NodeType] = None\n    \"\"\"None if it is the root, otherwise parent node\"\"\"\n    edge: Optional[EdgeWithMetadata[NodeType, EdgeMetadataType]] = None\n    \"\"\"None if it is the root, otherwise parent-&gt;self edge\"\"\"\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.traversal.TraversalNode.edge","title":"<code>edge = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>None if it is the root, otherwise parent-&gt;self edge</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.traversal.TraversalNode.node","title":"<code>node</code>  <code>instance-attribute</code>","text":"<p>Node itself</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.traversal.TraversalNode.parent","title":"<code>parent = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>None if it is the root, otherwise parent node</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.base.BaseNode","title":"<code>BaseNode</code>","text":"<p>               Bases: <code>UUIDHashable</code>, <code>Serializable</code></p> <p>Base node class.</p> Source code in <code>puku_core/graphs/knowledge_trees/nodes/base.py</code> <pre><code>class BaseNode(UUIDHashable, Serializable):\n    \"\"\"Base node class.\"\"\"\n\n    def __hash__(self) -&gt; int:\n        return super().__hash__()\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.markdown.MarkdownNode","title":"<code>MarkdownNode</code>","text":"<p>               Bases: <code>TrueTreeNode[MarkdownEdgeMetadata]</code></p> <p>Node that stores markdown data</p> Source code in <code>puku_core/graphs/knowledge_trees/nodes/markdown.py</code> <pre><code>class MarkdownNode(TrueTreeNode[MarkdownEdgeMetadata]):\n    \"\"\"Node that stores markdown data\"\"\"\n\n    title: str\n    \"\"\"For use as reference\"\"\"\n\n    description: str\n    \"\"\"What to store inside\"\"\"\n\n    data: MarkdownDocument\n    \"\"\"Stored data\"\"\"\n\n    def __hash__(self) -&gt; int:\n        return super().__hash__()\n</code></pre>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.markdown.MarkdownNode.data","title":"<code>data</code>  <code>instance-attribute</code>","text":"<p>Stored data</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.markdown.MarkdownNode.description","title":"<code>description</code>  <code>instance-attribute</code>","text":"<p>What to store inside</p>"},{"location":"core/api/#puku_core.graphs.knowledge_trees.nodes.markdown.MarkdownNode.title","title":"<code>title</code>  <code>instance-attribute</code>","text":"<p>For use as reference</p>"},{"location":"deployment/api/","title":"API Reference","text":""},{"location":"deployment/api/#puku_deployment.python.environment.create_packed_conda_environment","title":"<code>create_packed_conda_environment(path, dependencies, python_version='3.12', clean_cache=True)</code>","text":"<p>Creates a temporary conda environment with complete isolation, installs dependencies, packs it, and cleans up without any traces.</p> <p>Ensures: - PYTHONNOUSERSITE=True prevents user-site packages - Isolated package cache in temp directory - Full cleanup of all temporary artifacts - Optional global cache cleaning</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Output path for the .tar.gz environment</p> required <code>dependencies</code> <code>list[str]</code> <p>List of packages (e.g., [\"numpy\", \"pandas\"])</p> required <code>python_version</code> <code>str</code> <p>Python version string</p> <code>'3.12'</code> <code>clean_cache</code> <code>bool</code> <p>Clean global conda cache after operation</p> <code>True</code> Source code in <code>puku_deployment/python/environment.py</code> <pre><code>def create_packed_conda_environment(\n    path: str,\n    dependencies: list[str],\n    python_version: str = \"3.12\",\n    clean_cache: bool = True,\n):\n    \"\"\"\n    Creates a temporary conda environment with complete isolation,\n    installs dependencies, packs it, and cleans up without any traces.\n\n    Ensures:\n    - PYTHONNOUSERSITE=True prevents user-site packages\n    - Isolated package cache in temp directory\n    - Full cleanup of all temporary artifacts\n    - Optional global cache cleaning\n\n    Args:\n        path: Output path for the .tar.gz environment\n        dependencies: List of packages (e.g., [\"numpy\", \"pandas\"])\n        python_version: Python version string\n        clean_cache: Clean global conda cache after operation\n    \"\"\"\n    # Create isolated environment configuration\n    env = os.environ.copy()\n    env[\"PYTHONNOUSERSITE\"] = \"1\"  # Prevent user-site package interference\n\n    with tempfile.TemporaryDirectory() as tmpdir:\n        env_path = os.path.join(tmpdir, \"temp_env\")\n        # Create isolated package cache\n        env[\"CONDA_PKGS_DIRS\"] = pkg_cache = os.path.join(tmpdir, \"conda_pkgs\")\n        os.makedirs(pkg_cache, exist_ok=True)\n\n        # Step 1: Create environment with isolated settings\n        create_cmd = [\n            \"conda\",\n            \"create\",\n            \"--yes\",\n            \"--quiet\",\n            \"--prefix\",\n            env_path,\n            \"--channel\",\n            \"conda-forge\",  # Add conda-forge as primary channel\n            f\"python={python_version}\",\n        ] + dependencies\n\n        subprocess.run(create_cmd, check=True, env=env)\n\n        # Step 2: Pack environment using same isolation\n        pack_cmd = [\"conda-pack\", \"--quiet\", \"--prefix\", env_path, \"--output\", path]\n        subprocess.run(pack_cmd, check=True, env=env)\n\n        # Step 3: Verify environment removal\n        shutil.rmtree(env_path, ignore_errors=True)\n\n    # Step 5: Optional global cache cleaning\n    if clean_cache:\n        clean_cmd = [\"conda\", \"clean\", \"--all\", \"--yes\", \"--quiet\"]\n        subprocess.run(clean_cmd, check=True)\n</code></pre>"},{"location":"deployment/api/#puku_deployment.triton.utils.onnx.add_batch_dimension","title":"<code>add_batch_dimension(model, batch_inputs=None, batch_dim='batch_size')</code>","text":"<p>Adds batch dimension to an ONNX model while preserving other dimensions.</p> Source code in <code>puku_deployment/triton/utils/onnx.py</code> <pre><code>@experimental()\ndef add_batch_dimension(\n    model: onnx.ModelProto,\n    batch_inputs: Optional[list[str]] = None,\n    batch_dim=\"batch_size\",\n) -&gt; onnx.ModelProto:\n    \"\"\"Adds batch dimension to an ONNX model while preserving other dimensions.\"\"\"\n\n    for input_tensor in chain(model.graph.input, model.graph.output):\n        if not ((batch_inputs is None) or (input_tensor.name in batch_inputs)):\n            continue\n        # Get the input tensor and its original dimensions\n        original_dims = input_tensor.type.tensor_type.shape.dim  # This was missing!\n\n        # Create new shape object\n        new_shape = input_tensor.type.tensor_type.shape\n\n        # Clear existing dimensions\n        new_shape.ClearField(\"dim\")\n\n        # 1. Add batch dimension first\n        batch = new_shape.dim.add()\n        if isinstance(batch_dim, int):\n            batch.dim_value = batch_dim  # Fixed batch size\n        else:\n            batch.dim_param = batch_dim  # Dynamic batch size ('batch_size' or 'N')\n\n        # 2. Copy remaining dimensions from original\n        for orig_dim in original_dims:\n            new_dim = new_shape.dim.add()\n\n            # Handle defined dimensions\n            if orig_dim.HasField(\"dim_param\"):\n                new_dim.dim_param = orig_dim.dim_param\n            elif orig_dim.HasField(\"dim_value\"):\n                new_dim.dim_value = orig_dim.dim_value\n            else:\n                # Handle undefined dimensions\n                new_dim.dim_param = f\"dim_{len(new_shape.dim)-1}\"  # Default naming\n\n    # Run shape inference\n    return shape_inference.infer_shapes(model)\n</code></pre>"},{"location":"deployment/api/#puku_deployment.triton.utils.onnx.sequential","title":"<code>sequential(first_model, second_model, io_map=None)</code>","text":"<p>Merger two onnx models. Discussed in: https://github.com/onnx/onnx/issues/5006#issuecomment-1500402402</p> Source code in <code>puku_deployment/triton/utils/onnx.py</code> <pre><code>def sequential(\n    first_model: onnx.ModelProto,\n    second_model: onnx.ModelProto,\n    io_map: Optional[dict[str, str]] = None,\n) -&gt; onnx.ModelProto:\n    \"\"\"Merger two onnx models. Discussed in:\n    https://github.com/onnx/onnx/issues/5006#issuecomment-1500402402\n    \"\"\"\n    inputs = convert_onnx_arguments_to_spox(first_model.graph.input)\n\n    if not io_map:\n        io_map = {\n            name: name\n            for name in convert_onnx_arguments_to_spox(second_model.graph.input).keys()\n        }\n\n    intermediate = inline(first_model)(**inputs)\n\n    intermediate = {\n        input_name: intermediate[output_name]\n        for input_name, output_name in io_map.items()\n    }\n\n    outputs = inline(second_model)(**intermediate)\n    combined = build(inputs=inputs, outputs=outputs)\n    return combined\n</code></pre>"},{"location":"deployment/api/#puku_deployment.triton.models.base.TritonEnsembleModel","title":"<code>TritonEnsembleModel</code>","text":"<p>               Bases: <code>TritonModel</code></p> <p>Triton ensemble model, see here: https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/ensemble_models.html#ensemble-models</p> Source code in <code>puku_deployment/triton/models/base.py</code> <pre><code>class TritonEnsembleModel(TritonModel):\n    \"\"\"Triton ensemble model, see here:\n    https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/ensemble_models.html#ensemble-models\n    \"\"\"\n\n    config: TritonEnsembleModelConfig\n\n    @classmethod\n    def from_configs(\n        cls,\n        name: str,\n        configs: list[TritonModelConfig],\n        io_maps: Optional[list[tuple[dict[str, str], dict[str, str]]]] = None,\n    ) -&gt; Self:\n        if io_maps is None:\n            io_maps = []\n            for config in configs:\n                input_maps = dict()\n                output_maps = dict()\n\n                for tensor_config in config.input:\n                    input_maps[tensor_config.name] = tensor_config.name\n\n                for tensor_config in config.output:\n                    output_maps[tensor_config.name] = tensor_config.name\n\n                io_maps.append((input_maps, output_maps))\n\n        input_flow = set()\n        output_flow = set()\n\n        possible_inputs: dict[str, TritonTensorConfig] = dict()\n        possible_outputs: dict[str, TritonTensorConfig] = dict()\n\n        for io_map, config in zip(io_maps, configs):\n            input_map, output_map = io_map\n\n            for internal, external in input_map.items():\n                for _input in config.input:\n                    if _input.name == internal:\n                        possible_inputs[external] = _input\n                        break\n\n            for internal, external in output_map.items():\n                for _output in config.output:\n                    if _output.name == internal:\n                        possible_outputs[external] = _output\n                        break\n\n            input_flow.update(output_map.values())\n            output_flow.update(input_map.values())\n\n        inputs: list[TritonTensorConfig] = []\n        outputs: list[TritonTensorConfig] = []\n\n        for possible_input, tensor_config in possible_inputs.items():\n            if not (possible_input in input_flow):\n                inputs.append(tensor_config)\n\n        for possible_output, tensor_config in possible_outputs.items():\n            if not (possible_output in output_flow):\n                outputs.append(tensor_config)\n\n        steps: list[TritonEnsembleStepConfig] = []\n        for io_map, config in zip(io_maps, configs):\n            input_map, output_map = io_map\n\n            input_maps = [\n                DataMapType(key=key, value=value) for key, value in input_map.items()\n            ]\n            output_maps = [\n                DataMapType(key=key, value=value) for key, value in output_map.items()\n            ]\n\n            steps.append(\n                TritonEnsembleStepConfig(\n                    model_name=config.name,\n                    input_map=DataMaps(maps=input_maps),\n                    output_map=DataMaps(maps=output_maps),\n                )\n            )\n\n        return cls(\n            config=TritonEnsembleModelConfig(\n                name=name,\n                input=inputs,\n                output=outputs,\n                ensemble_scheduling=StepMaps(maps=[StepMapType(step=steps)]),\n            )\n        )\n\n    def get_config(self, **kwargs) -&gt; TritonEnsembleModelConfig:\n        return self.config\n\n    def save(self, model_repository_path: str, **kwargs) -&gt; TritonEnsembleModelConfig:\n        config = self.config\n        config.save(model_repository_path=model_repository_path)\n        return config\n</code></pre>"},{"location":"deployment/api/#puku_deployment.triton.models.base.TritonPythonModel","title":"<code>TritonPythonModel</code>","text":"<p>               Bases: <code>TritonModel</code></p> Source code in <code>puku_deployment/triton/models/base.py</code> <pre><code>class TritonPythonModel(TritonModel):\n    python_version: str = \"3.12\"\n    dependencies: list[str] = Field(default_factory=list)\n\n    def get_model_code(self) -&gt; str:\n        \"\"\"Get model.py code in the form of\n        https://github.com/triton-inference-server/python_backend#usage\n        \"\"\"\n        raise NotImplementedError\n\n    def export_python(self, path: str) -&gt; None:\n        code = self.get_model_code()\n        with open(path, \"w\") as f:\n            f.write(code)\n\n    def export_conda_environment(self, path: str):\n        create_packed_conda_environment(\n            path=path,\n            dependencies=self.dependencies,\n            python_version=self.python_version,\n        )\n\n    def get_config(self, **kwargs) -&gt; TritonPythonModelConfig:\n        raise NotImplementedError\n\n    def save(self, model_repository_path: str, **kwargs) -&gt; TritonPythonModelConfig:\n        conda_environment_name = f\"python{self.python_version}.tar.gz\"\n\n        # Configuration\n        config = self.get_config(**kwargs)\n        config.parameters = Parameters(\n            key=\"EXECUTION_ENV_PATH\",\n            value=f\"$$TRITON_MODEL_DIRECTORY/{conda_environment_name}\",\n        )\n\n        # Set up paths\n        model_dir = os.path.join(model_repository_path, config.name)\n        model_path = os.path.join(model_dir, \"1\", \"model.py\")\n        conda_environment_path = os.path.join(model_dir, conda_environment_name)\n\n        # Export\n        create_path(model_path)\n        self.export_conda_environment(path=conda_environment_path)\n        self.export_python(path=model_path)\n        config.save(model_repository_path=model_repository_path)\n\n        return config\n</code></pre>"},{"location":"deployment/api/#puku_deployment.triton.models.base.TritonPythonModel.get_model_code","title":"<code>get_model_code()</code>","text":"<p>Get model.py code in the form of https://github.com/triton-inference-server/python_backend#usage</p> Source code in <code>puku_deployment/triton/models/base.py</code> <pre><code>def get_model_code(self) -&gt; str:\n    \"\"\"Get model.py code in the form of\n    https://github.com/triton-inference-server/python_backend#usage\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"puku/api/","title":"API Reference","text":""},{"location":"puku/api/#puku.embeddings.triton.TritonEmbeddings","title":"<code>TritonEmbeddings</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Embeddings</code></p> <p>A client for getting text embeddings from a Triton Inference Server.</p> Source code in <code>puku/embeddings/triton.py</code> <pre><code>class TritonEmbeddings(BaseModel, Embeddings):\n    \"\"\"\n    A client for getting text embeddings from a Triton Inference Server.\n    \"\"\"\n\n    url: str = \"localhost:8001\"\n    model_name: str\n\n    input_name: str\n    output_name: str\n\n    def model_post_init(self, context: Any) -&gt; None:\n        self._client = grpcclient.InferenceServerClient(url=self.url)\n\n        # Verify server is ready\n        if not self._client.is_server_ready():\n            raise ConnectionError(f\"Triton server at {self.url} is not ready\")\n\n        # Verify model is ready\n        if not self._client.is_model_ready(self.model_name):\n            raise ValueError(f\"Model {self.model_name} is not ready\")\n\n    def embed_documents(self, texts: List[str]) -&gt; List[List[float]]:\n        # Create input object for text strings\n        text_array = np.array(texts, dtype=object).reshape(-1)\n        input_text = grpcclient.InferInput(\n            self.input_name,\n            text_array.shape,\n            np_to_triton_dtype(text_array.dtype),\n        )\n        input_text.set_data_from_numpy(text_array)\n\n        # Create output object for embeddings\n        output_emb = grpcclient.InferRequestedOutput(self.output_name)\n\n        # Send request to server - Triton will handle batching automatically\n        response = self._client.infer(\n            model_name=self.model_name,\n            inputs=[input_text],\n            outputs=[output_emb],\n        )\n\n        # Get embeddings from response\n        embeddings: np.ndarray[np.floating] = response.as_numpy(self.output_name)  # type: ignore\n        return embeddings.tolist()\n\n    def embed_query(self, text: str) -&gt; List[float]:\n        return self.embed_documents([text])[0]\n\n    def __del__(self):\n        \"\"\"Clean up Triton client when object is deleted.\"\"\"\n        if hasattr(self, \"_client\"):\n            self._client.close()\n</code></pre>"},{"location":"puku/api/#puku.embeddings.triton.TritonEmbeddings.__del__","title":"<code>__del__()</code>","text":"<p>Clean up Triton client when object is deleted.</p> Source code in <code>puku/embeddings/triton.py</code> <pre><code>def __del__(self):\n    \"\"\"Clean up Triton client when object is deleted.\"\"\"\n    if hasattr(self, \"_client\"):\n        self._client.close()\n</code></pre>"},{"location":"puku/api/#puku.document_transformers.pandoc.PandocBlobTransformer","title":"<code>PandocBlobTransformer</code>","text":"<p>               Bases: <code>SubprocessBlobTransformer</code></p> <p>Runs pandoc to convert extension.</p> Source code in <code>puku/document_transformers/pandoc.py</code> <pre><code>class PandocBlobTransformer(SubprocessBlobTransformer):\n    \"\"\"Runs pandoc to convert extension.\"\"\"\n\n    from_format: str\n    to_format: str\n\n    def _get_output_path(\n        self, blob: Blob, output_dir: Optional[PathLike] = None\n    ) -&gt; str:\n        \"\"\"Get path for output blob.\"\"\"\n\n        # all blobs must contain path\n        if blob.path is None:\n            raise ValueError(f\"Blob {blob} does not have path.\")\n\n        # change extension\n        without_extension = os.path.splitext(blob.path)[0]\n\n        if not without_extension:\n            raise ValueError(f\"{blob.path} file has bad name\")\n\n        output_path = (\n            f\"{without_extension}.{PANDOC_FORMAT_TO_EXTENSION[self.to_format]}\"\n        )\n\n        # change folder\n        if not (output_dir is None):\n            output_path = os.path.join(output_dir, os.path.basename(output_path))\n\n        return output_path\n\n    def get_output_blob(\n        self, blob: Blob, output_dir: Optional[PathLike] = None, **kwargs\n    ) -&gt; Blob:\n        \"\"\"Creates new blob from output path.\"\"\"\n\n        return Blob.from_path(\n            path=self._get_output_path(blob=blob, output_dir=output_dir)\n        )\n\n    def get_command(\n        self,\n        blob: Blob,\n        output_dir: Optional[PathLike] = None,\n        standalone: bool = False,\n        **kwargs,\n    ) -&gt; list[str]:\n        \"\"\"Creates pandoc command.\"\"\"\n\n        output_path = self._get_output_path(blob=blob, output_dir=output_dir)\n\n        return (\n            [\"pandoc\"]\n            + ([\"-s\"] if standalone else [])\n            + [str(blob.path)]\n            + [\"-f\", self.from_format]\n            + [\"-t\", self.to_format]\n            + [\"-o\", output_path]\n        )\n\n    def transform_blobs(\n        self,\n        blobs: Sequence[Blob],\n        output_dir: Optional[PathLike] = None,\n        standalone: bool = False,\n        **kwargs: Any,\n    ) -&gt; Sequence[Blob]:\n        \"\"\"Convert blob extensions using pandoc.\n\n        Args:\n            blobs (Sequence[Blob]): Blobs to be converted. Must contain path.\n            output_dir (Optional[PathLike], optional): The directory for saving the results. \\\n                If not, the files are saved in the same location.\n            standalone (bool, optional): Pandoc standalone flag.\n\n        Returns:\n            Sequence[Blob]: _description_\n        \"\"\"\n\n        if shutil.which(\"pandoc\") is None:\n            raise FileNotFoundError(\n                \"Pandoc is not installed. Please install it from https://pandoc.org/installing.html\"\n            )\n\n        return super().transform_blobs(\n            blobs=blobs, output_dir=output_dir, standalone=standalone, **kwargs\n        )\n</code></pre>"},{"location":"puku/api/#puku.document_transformers.pandoc.PandocBlobTransformer.get_command","title":"<code>get_command(blob, output_dir=None, standalone=False, **kwargs)</code>","text":"<p>Creates pandoc command.</p> Source code in <code>puku/document_transformers/pandoc.py</code> <pre><code>def get_command(\n    self,\n    blob: Blob,\n    output_dir: Optional[PathLike] = None,\n    standalone: bool = False,\n    **kwargs,\n) -&gt; list[str]:\n    \"\"\"Creates pandoc command.\"\"\"\n\n    output_path = self._get_output_path(blob=blob, output_dir=output_dir)\n\n    return (\n        [\"pandoc\"]\n        + ([\"-s\"] if standalone else [])\n        + [str(blob.path)]\n        + [\"-f\", self.from_format]\n        + [\"-t\", self.to_format]\n        + [\"-o\", output_path]\n    )\n</code></pre>"},{"location":"puku/api/#puku.document_transformers.pandoc.PandocBlobTransformer.get_output_blob","title":"<code>get_output_blob(blob, output_dir=None, **kwargs)</code>","text":"<p>Creates new blob from output path.</p> Source code in <code>puku/document_transformers/pandoc.py</code> <pre><code>def get_output_blob(\n    self, blob: Blob, output_dir: Optional[PathLike] = None, **kwargs\n) -&gt; Blob:\n    \"\"\"Creates new blob from output path.\"\"\"\n\n    return Blob.from_path(\n        path=self._get_output_path(blob=blob, output_dir=output_dir)\n    )\n</code></pre>"},{"location":"puku/api/#puku.document_transformers.pandoc.PandocBlobTransformer.transform_blobs","title":"<code>transform_blobs(blobs, output_dir=None, standalone=False, **kwargs)</code>","text":"<p>Convert blob extensions using pandoc.</p> <p>Parameters:</p> Name Type Description Default <code>blobs</code> <code>Sequence[Blob]</code> <p>Blobs to be converted. Must contain path.</p> required <code>output_dir</code> <code>Optional[PathLike]</code> <p>The directory for saving the results.                 If not, the files are saved in the same location.</p> <code>None</code> <code>standalone</code> <code>bool</code> <p>Pandoc standalone flag.</p> <code>False</code> <p>Returns:</p> Type Description <code>Sequence[Blob]</code> <p>Sequence[Blob]: description</p> Source code in <code>puku/document_transformers/pandoc.py</code> <pre><code>def transform_blobs(\n    self,\n    blobs: Sequence[Blob],\n    output_dir: Optional[PathLike] = None,\n    standalone: bool = False,\n    **kwargs: Any,\n) -&gt; Sequence[Blob]:\n    \"\"\"Convert blob extensions using pandoc.\n\n    Args:\n        blobs (Sequence[Blob]): Blobs to be converted. Must contain path.\n        output_dir (Optional[PathLike], optional): The directory for saving the results. \\\n            If not, the files are saved in the same location.\n        standalone (bool, optional): Pandoc standalone flag.\n\n    Returns:\n        Sequence[Blob]: _description_\n    \"\"\"\n\n    if shutil.which(\"pandoc\") is None:\n        raise FileNotFoundError(\n            \"Pandoc is not installed. Please install it from https://pandoc.org/installing.html\"\n        )\n\n    return super().transform_blobs(\n        blobs=blobs, output_dir=output_dir, standalone=standalone, **kwargs\n    )\n</code></pre>"}]}